# Stage 2: Fusion Multimodale
# Ajout progressif des modalités image/audio/video

# Model Configuration - Multimodal Stage
model_name: "ultra-ai-stage2"
model_variant: "ultra-edge"
d_model: 512
vocab_size: 50432
max_seq_length: 100000

# Architecture - Balanced Multimodal
mamba_ratio: 0.70    # Backbone principal
attention_ratio: 0.20 # Plus d'attention pour multimodal
moe_ratio: 0.08      # MoE activé
multimodal_ratio: 0.02 # Fusion multimodale

# Mamba-2 Configuration
mamba_layers: 12
mamba_d_state: 128
mamba_d_conv: 4
mamba_expand: 2
mamba_dt_rank: "auto"

# Attention Configuration (Enhanced)
attention_layers: 2
attention_heads: 16
attention_type: "linear"

# MoE Configuration (Lightweight)
moe_layers: 4
num_experts: 8  # Réduit pour local
moe_top_k: 2
expert_capacity_factor: 1.25
moe_balance_loss_weight: 0.01

# Multimodal Configuration
modalities: ["text", "image", "audio", "video"]
image_size: 224
audio_sample_rate: 16000
video_frames: 8
max_image_tokens: 256  # Réduit pour local
max_audio_tokens: 512
max_video_tokens: 128

# Training Configuration (From stage1 checkpoint)
resume_from_checkpoint: "./checkpoints/stage1/best_model.pt"
freeze_backbone: false  # Allow fine-tuning
freeze_embeddings: true  # Keep text embeddings stable

batch_size: 1  # Réduit pour multimodal
micro_batch_size: 1
gradient_accumulation_steps: 64  # Effective batch = 64
max_gradient_accumulation_tokens: 200000  # Réduit

learning_rate: 0.00005  # Plus conservateur
min_learning_rate: 0.000005
weight_decay: 0.01
max_grad_norm: 1.0
num_epochs: 1  # Plus court
warmup_ratio: 0.2

# Optimizer
optimizer: "adamw"
beta1: 0.9
beta2: 0.95
eps: 0.00000001
fused_optimizer: true

# Scheduler
scheduler: "cosine"
warmup_steps: 1000

# Training Efficiency
mixed_precision: "fp16"
gradient_checkpointing: true
selective_checkpointing: true
use_flash_attention: false
compile_model: false

# Data Configuration (Multimodal)
train_data_path: "./data/processed"
val_data_path: "./data/processed"
tokenizer_name: "microsoft/DialoGPT-large"

# Multimodal Data Loading
multimodal_sampling_strategy: "balanced"  # Balance entre modalités
text_to_multimodal_ratio: 0.7  # 70% texte, 30% multimodal
max_multimodal_tokens: 1000
image_augmentation: true
audio_augmentation: false  # Peut causer instabilité

# Data Loading (Optimized for multimodal)
sequence_bucketing: false  # Plus complexe avec multimodal
dynamic_padding: true
max_tokens_per_batch: 200000
dataloader_num_workers: 1  # Réduit pour stabilité
prefetch_factor: 1

# Checkpointing
output_dir: "./checkpoints/stage2"
save_strategy: "steps"
save_steps: 800
save_total_limit: 3
load_best_model_at_end: true

# Logging & Monitoring
logging_strategy: "steps"
logging_steps: 25
eval_strategy: "steps" 
eval_steps: 400
eval_delay: 800

# Monitoring
use_wandb: true
wandb_project: "ultra-ai-stage2"
wandb_run_name: "multimodal-fusion"
wandb_tags: ["stage2", "multimodal", "fusion"]

use_tensorboard: true
tensorboard_log_dir: "./logs/stage2"

# Enhanced Metrics
monitor_metrics:
  - "loss/total"
  - "loss/text"
  - "loss/multimodal"
  - "loss/moe_auxiliary"
  - "metrics/perplexity"
  - "metrics/tokens_per_sec"
  - "multimodal/image_accuracy"
  - "multimodal/fusion_score"
  - "hardware/gpu_memory"

# Early Stopping (More patient)
early_stopping:
  enabled: true
  patience: 5
  min_delta: 0.005
  restore_best_weights: true

# Multimodal Evaluation
evaluation:
  metrics: ["perplexity", "multimodal_coherence"]
  generation_samples: 5
  max_gen_length: 100
  temperature: 0.8
  multimodal_eval: true
  image_caption_eval: true

# Loss Configuration (Multimodal)
loss_weights:
  text_loss: 1.0
  image_loss: 0.5
  audio_loss: 0.3
  video_loss: 0.2
  moe_auxiliary_loss: 0.1
  contrastive_loss: 0.2  # Pour alignement multimodal

# Hardware (Multimodal needs more memory)
hardware:
  fp16_mixed_precision: true
  bf16_mixed_precision: false
  tf32_enabled: true
  cudnn_benchmark: false  # Plus stable pour multimodal

# Memory Management (Aggressive)
cpu_offload_params: true  # Nécessaire pour multimodal
cpu_offload_optimizer: true
pin_memory: false  # Peut causer OOM
gradient_accumulation_cpu_offload: true

# Distributed
parallelism_strategy: "none"
distributed: false

# Specialized Multimodal Settings
multimodal_training:
  cross_modal_attention: true
  modality_dropout: 0.1  # Regularization
  temperature_scaling: true
  contrastive_learning: true
  hard_negative_mining: false  # Peut déstabiliser

# Progressive Training Strategy
progressive_training:
  enabled: true
  stages:
    - modality: "image"
      steps: 2000
      learning_rate_multiplier: 0.5
    - modality: "audio" 
      steps: 1500
      learning_rate_multiplier: 0.3
    - modality: "video"
      steps: 1000
      learning_rate_multiplier: 0.2
    - modality: "all"
      steps: 2000
      learning_rate_multiplier: 1.0

# Quality Control
quality_control:
  skip_corrupted_samples: true
  max_retries: 3
  validate_multimodal_alignment: true
  min_multimodal_score: 0.3

# Resource Monitoring (Critical for multimodal)
resource_monitoring:
  log_gpu_memory: true
  log_cpu_memory: true
  log_multimodal_cache: true
  alert_thresholds:
    gpu_memory: 0.95
    cpu_memory: 0.90